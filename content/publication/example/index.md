---
abstract: >-
  Eye gaze estimation is increasingly demanded by recent intelligent systems to
  facilitate a range of interactive applications. Unfortunately, learning the
  highly complicated regression from a single eye image to the gaze direction is
  not trivial. Thus, the problem is yet to be solved efficiently. Inspired

  by the two-eye asymmetry as two eyes of the same person may appear uneven, we propose the face-based asymmetric regression-evaluation network (FARE-Net) to optimize the gaze estimation results by considering the difference between left and right eyes. The proposed method includes one face-based asymmetric regression network (FAR-Net) and one evaluation network (E-Net). The FAR-Net predicts 3D gaze directions for both eyes and is trained with the asymmetric mechanism, which asymmetrically weights and sums the loss generated by two-eye gaze directions. With the asymmetric mechanism, the FAR-Net utilizes the eyes that can achieve high performance to optimize network. The E-Net learns the reliabilities of two eyes to balance the learning of the asymmetric mechanism and symmetric mechanism. Our FARE-Net achieves leading performances on MPIIGaze, EyeDiap and RT-Gene datasets. Additionally, we investigate the effectiveness of FARE-Net by analyzing the distribution of errors and ablation study.
slides: ""
url_pdf: ""
publication_types:
  - "2"
authors:
  - Yihua Cheng
  - Xucong Zhang
  - Feng Lu
  - Yoichi Sato
author_notes: []
publication: IEEE Transactions on Image Processing
summary: "We observe the two-eye asymmetry in gaze estimation and detaillly
  explore it on this paper. "
url_dataset: ""
url_project: ""
publication_short: IEEE TIP
url_source: ""
url_video: ""
title: Gaze Estimation by Exploring Two-Eye Asymmetry
doi: ""
featured: false
tags: []
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
  filename: asymmetry.png
date: 2013-07-01T00:00:00Z
url_slides: ""
publishDate: 2017-01-01T00:00:00Z
url_poster: ""
url_code: ""
---

{{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
